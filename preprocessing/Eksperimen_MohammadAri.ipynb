{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eksperimen Machine Learning - Ethereum Fraud Detection\n",
    "### Mohammad Ari Alexander Aziz\n",
    "\n",
    "## Tujuan Eksperimen\n",
    "Notebook ini berisi eksperimen lengkap untuk deteksi fraud pada transaksi Ethereum, meliputi:\n",
    "1. Data Loading\n",
    "2. Exploratory Data Analysis (EDA)\n",
    "3. Data Preprocessing\n",
    "4. Model Building & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, \n",
    "    classification_report, \n",
    "    roc_auc_score, \n",
    "    roc_curve, \n",
    "    auc,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "import pickle\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "Dataset berisi transaksi Ethereum dengan label fraud (FLAG=1) dan non-fraud (FLAG=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('../transaction_dataset.csv', index_col=0)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nDataset info:\")\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "### 3.1 Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Index and Address columns (not needed for modeling)\n",
    "df = df.iloc[:, 2:]\n",
    "print(f\"Shape after removing Index and Address: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Target Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze target distribution\n",
    "print(\"Target Distribution:\")\n",
    "print(df['FLAG'].value_counts())\n",
    "print(f\"\\nFraud percentage: {df['FLAG'].mean() * 100:.2f}%\")\n",
    "\n",
    "# Visualize target distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "labels = ['Non-Fraud (0)', 'Fraud (1)']\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "counts = df['FLAG'].value_counts()\n",
    "\n",
    "plt.pie(counts, labels=labels, autopct='%1.2f%%', colors=colors, startangle=90)\n",
    "plt.title('Target Distribution - Ethereum Fraud Detection', fontsize=14, fontweight='bold')\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservation: Dataset is imbalanced, SMOTE will be used later.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percent = (missing_values / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values,\n",
    "    'Percentage': missing_percent\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "\n",
    "print(\"Features with Missing Values:\")\n",
    "print(missing_df)\n",
    "\n",
    "# Visualize missing values pattern\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n",
    "plt.title('Missing Values Pattern', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary of numerical features\n",
    "print(\"Statistical Summary:\")\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Feature Variance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for zero variance features\n",
    "numericals = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "variance = df[numericals].var()\n",
    "zero_var_features = variance[variance == 0]\n",
    "\n",
    "print(\"Features with Zero Variance:\")\n",
    "print(zero_var_features)\n",
    "print(f\"\\nTotal features with zero variance: {len(zero_var_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for numerical features\n",
    "plt.figure(figsize=(20, 16))\n",
    "corr = df[numericals].corr()\n",
    "\n",
    "# Create mask for upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "sns.heatmap(corr, mask=mask, cmap='RdBu_r', center=0, \n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix - Numerical Features', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find highly correlated features (>0.9)\n",
    "high_corr = []\n",
    "for i in range(len(corr.columns)):\n",
    "    for j in range(i+1, len(corr.columns)):\n",
    "        if abs(corr.iloc[i, j]) > 0.9:\n",
    "            high_corr.append((corr.columns[i], corr.columns[j], corr.iloc[i, j]))\n",
    "\n",
    "print(f\"\\nHighly Correlated Feature Pairs (|correlation| > 0.9):\")\n",
    "for feat1, feat2, corr_val in high_corr:\n",
    "    print(f\"{feat1} <-> {feat2}: {corr_val:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Feature Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical features\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "print(f\"Categorical columns: {list(categorical_cols)}\")\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col} - Unique values: {df[col].nunique()}\")\n",
    "    print(df[col].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing\n",
    "\n",
    "### 4.1 Handle Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop categorical features (too many unique values, not suitable for modeling)\n",
    "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Dropping categorical features: {categorical_features}\")\n",
    "df = df.drop(categorical_features, axis=1)\n",
    "print(f\"\\nShape after dropping categorical features: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with median\n",
    "print(\"Filling missing values with median...\")\n",
    "df = df.fillna(df.median())\n",
    "\n",
    "# Verify no missing values remain\n",
    "print(f\"\\nMissing values after imputation: {df.isnull().sum().sum()}\")\n",
    "print(f\"Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Remove Zero Variance Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features with zero variance\n",
    "zero_var_cols = df.var()[df.var() == 0].index.tolist()\n",
    "print(f\"Removing {len(zero_var_cols)} zero variance features:\")\n",
    "print(zero_var_cols)\n",
    "\n",
    "df = df.drop(zero_var_cols, axis=1)\n",
    "print(f\"\\nShape after removing zero variance features: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Remove Highly Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop highly correlated features to reduce multicollinearity\n",
    "drop_features = [\n",
    "    'total transactions (including tnx to create contract',\n",
    "    'total ether sent contracts',\n",
    "    'max val sent to contract',\n",
    "    ' ERC20 avg val rec',\n",
    "    ' ERC20 max val rec',\n",
    "    ' ERC20 min val rec',\n",
    "    ' ERC20 uniq rec contract addr',\n",
    "    'max val sent',\n",
    "    ' ERC20 avg val sent',\n",
    "    ' ERC20 min val sent',\n",
    "    ' ERC20 max val sent',\n",
    "    ' Total ERC20 tnxs',\n",
    "    'avg value sent to contract',\n",
    "    'Unique Sent To Addresses',\n",
    "    'Unique Received From Addresses',\n",
    "    'total ether received',\n",
    "    ' ERC20 uniq sent token name',\n",
    "    'min value received',\n",
    "    'min val sent',\n",
    "    ' ERC20 uniq rec addr'\n",
    "]\n",
    "\n",
    "# Only drop features that exist in the dataframe\n",
    "existing_drop_features = [f for f in drop_features if f in df.columns]\n",
    "print(f\"Dropping {len(existing_drop_features)} highly correlated features\")\n",
    "\n",
    "df = df.drop(existing_drop_features, axis=1)\n",
    "print(f\"\\nShape after removing correlated features: {df.shape}\")\n",
    "print(f\"Remaining features: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Remove Low-Information Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for features with very low unique values\n",
    "for col in df.columns:\n",
    "    if col != 'FLAG':\n",
    "        unique_count = df[col].nunique()\n",
    "        if unique_count < 10:\n",
    "            print(f\"\\n{col}: {unique_count} unique values\")\n",
    "            print(df[col].value_counts())\n",
    "\n",
    "# Drop features with mostly zeros\n",
    "low_info_features = ['min value sent to contract', ' ERC20 uniq sent addr.1']\n",
    "existing_low_info = [f for f in low_info_features if f in df.columns]\n",
    "if existing_low_info:\n",
    "    print(f\"\\nDropping low-information features: {existing_low_info}\")\n",
    "    df = df.drop(existing_low_info, axis=1)\n",
    "\n",
    "print(f\"\\nFinal shape after preprocessing: {df.shape}\")\n",
    "print(f\"Final features: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed data\n",
    "output_path = 'ethereum_fraud_preprocessing.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Preprocessed data saved to: {output_path}\")\n",
    "print(f\"Final dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Preparation for Modeling\n",
    "\n",
    "### 5.1 Split Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df.drop('FLAG', axis=1)\n",
    "y = df['FLAG']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"\\nTraining target distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nTest target distribution:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PowerTransformer to normalize features\n",
    "scaler = PowerTransformer()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Features scaled using PowerTransformer\")\n",
    "print(f\"Scaled training set shape: {X_train_scaled.shape}\")\n",
    "print(f\"Scaled test set shape: {X_test_scaled.shape}\")\n",
    "\n",
    "# Save the scaler for later use\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"\\nScaler saved to: scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Handle Class Imbalance with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to handle class imbalance\n",
    "print(\"Before SMOTE:\")\n",
    "print(f\"Training set shape: {X_train_scaled.shape}\")\n",
    "print(f\"Target distribution:\\n{y_train.value_counts()}\")\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\nAfter SMOTE:\")\n",
    "print(f\"Training set shape: {X_train_resampled.shape}\")\n",
    "print(f\"Target distribution:\\n{pd.Series(y_train_resampled).value_counts()}\")\n",
    "\n",
    "# Visualize the effect of SMOTE\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "y_train.value_counts().plot(kind='bar', ax=axes[0], color=['#2ecc71', '#e74c3c'])\n",
    "axes[0].set_title('Before SMOTE')\n",
    "axes[0].set_xlabel('Class')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xticklabels(['Non-Fraud', 'Fraud'], rotation=0)\n",
    "\n",
    "pd.Series(y_train_resampled).value_counts().plot(kind='bar', ax=axes[1], color=['#2ecc71', '#e74c3c'])\n",
    "axes[1].set_title('After SMOTE')\n",
    "axes[1].set_xlabel('Class')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_xticklabels(['Non-Fraud', 'Fraud'], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Building and Evaluation\n",
    "\n",
    "### 6.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression\n",
    "print(\"Training Logistic Regression...\")\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nLogistic Regression Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_test, y_pred_lr, target_names=['Non-Fraud', 'Fraud']))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_lr, display_labels=['Non-Fraud', 'Fraud'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix - Logistic Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "print(\"Training Random Forest...\")\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "rf_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_test, y_pred_rf, target_names=['Non-Fraud', 'Fraud']))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_rf, display_labels=['Non-Fraud', 'Fraud'])\n",
    "disp.plot(cmap='Greens')\n",
    "plt.title('Confusion Matrix - Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost\n",
    "print(\"Training XGBoost...\")\n",
    "xgb_model = xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "xgb_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nXGBoost Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_test, y_pred_xgb, target_names=['Non-Fraud', 'Fraud']))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_xgb, display_labels=['Non-Fraud', 'Fraud'])\n",
    "disp.plot(cmap='Oranges')\n",
    "plt.title('Confusion Matrix - XGBoost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': y_pred_lr,\n",
    "    'Random Forest': y_pred_rf,\n",
    "    'XGBoost': y_pred_xgb\n",
    "}\n",
    "\n",
    "results = []\n",
    "for model_name, predictions in models.items():\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(\"=\" * 80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Visualize comparison\n",
    "results_df.set_index('Model')[['Accuracy', 'Precision', 'Recall', 'F1-Score']].plot(kind='bar', figsize=(12, 6))\n",
    "plt.title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Model')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(loc='lower right')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify best model\n",
    "best_model_idx = results_df['F1-Score'].idxmax()\n",
    "best_model_name = results_df.loc[best_model_idx, 'Model']\n",
    "print(f\"\\nBest Model: {best_model_name} (F1-Score: {results_df.loc[best_model_idx, 'F1-Score']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 ROC Curve Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves for all models\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Logistic Regression\n",
    "y_proba_lr = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_proba_lr)\n",
    "auc_lr = auc(fpr_lr, tpr_lr)\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {auc_lr:.3f})')\n",
    "\n",
    "# Random Forest\n",
    "y_proba_rf = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_proba_rf)\n",
    "auc_rf = auc(fpr_rf, tpr_rf)\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {auc_rf:.3f})')\n",
    "\n",
    "# XGBoost\n",
    "y_proba_xgb = xgb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_proba_xgb)\n",
    "auc_xgb = auc(fpr_xgb, tpr_xgb)\n",
    "plt.plot(fpr_xgb, tpr_xgb, label=f'XGBoost (AUC = {auc_xgb:.3f})')\n",
    "\n",
    "# Random classifier line\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Comparison - All Models', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best performing model (XGBoost typically performs best)\n",
    "with open('xgboost_fraud_model.pkl', 'wb') as f:\n",
    "    pickle.dump(xgb_model, f)\n",
    "\n",
    "print(\"Best model saved to: xgboost_fraud_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Conclusions\n",
    "\n",
    "### Key Findings:\n",
    "1. **Dataset**: 9841 Ethereum transactions with ~22% fraud cases (imbalanced)\n",
    "2. **Preprocessing**: \n",
    "   - Removed categorical features with high cardinality\n",
    "   - Handled missing values with median imputation\n",
    "   - Removed zero variance and highly correlated features\n",
    "   - Applied PowerTransformer for feature scaling\n",
    "   - Used SMOTE for class imbalance\n",
    "3. **Models Tested**: Logistic Regression, Random Forest, XGBoost\n",
    "4. **Best Model**: XGBoost with highest recall for fraud detection\n",
    "\n",
    "### Next Steps:\n",
    "1. Create automation script (`automate_MohammadAri.py`)\n",
    "2. Implement hyperparameter tuning with MLflow\n",
    "3. Set up CI/CD pipeline\n",
    "4. Deploy model with monitoring"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
